{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install cufflinks\n",
    "#!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from IPython.core.debugger import set_trace\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot settings\n",
    "import plotly\n",
    "import cufflinks\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML, display_html\n",
    "\n",
    "# set formatting\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn')\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stock file\n",
    "df_raw = pd.read_csv('GE.csv', index_col = 0, parse_dates=True)\n",
    "\n",
    "# Look at data head\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at data tail\n",
    "df_raw.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look a shape of data\n",
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import file\n",
    "pandas_profiling.ProfileReport(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at data types\n",
    "df_raw.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Should it stay or should it go?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by date\n",
    "df = df_temp.groupby(by = 'Date').agg('Adj Close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change index to datetime\n",
    "df.index = pd.to_datetime(df_temp.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set frequency of time series\n",
    "df = df_temp.asfreq(freq='1D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the end of the data\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unused columns\n",
    "df = df.drop(['Close'], axis=1)\n",
    "df = df.drop(['Open'], axis=1)\n",
    "df = df.drop(['High'], axis=1)\n",
    "df = df.drop(['Low'], axis=1)\n",
    "df = df.drop(['Volume'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'Adj Close' column\n",
    "df = df.rename(columns = {'Adj Close' : 'ts'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time series data\n",
    "f, ax = plt.subplots(1,1)\n",
    "ax.plot(df_raw['Adj Close'])\n",
    "\n",
    "# Add title\n",
    "ax.set_title('Time-series graph for 1 time-series example')\n",
    "\n",
    "# Rotate x-labels\n",
    "ax.tick_params(axis = 'x', rotation = 45)\n",
    "\n",
    "# Show graph\n",
    "plt.show()\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ## Plot of Raw Adj Closing prices\n",
    "## df['Close'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of Adj Closing prices\n",
    "df['ts'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute and plot time series with interpolated missing values (non trading days)\n",
    "df = df.assign(InterpolateTime=df['ts'].interpolate(method='time'))\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ts'] = InterpolateTime=df['ts'].interpolate(method='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of Adj Closing prices\n",
    "df['ts'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.diff().head()\n",
    "# df['Return'] = df.Close - df.Open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute price changes from one day to the other\n",
    "df_diff = df.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of price change series from one day to the other (Adj Close)\n",
    "df_diff['ts'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ## Plot of price change series from one day to the other (Close)\n",
    "## df_diff['Close'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transormation\n",
    "df_transformed= np.log(df['ts'] / df['ts'].shift(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLot log transofrmation series\n",
    "df_transformed.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = df.index\n",
    "adj_close = df['ts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_close.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Applying statistical modeling and machine learning to perform time-series forecasting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at Stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "def test_stationarity(df, ts):\n",
    "    \"\"\"\n",
    "    Test stationarity using moving average statistics and Dickey-Fuller test\n",
    "    Source: https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/\n",
    "    \"\"\"\n",
    "    \n",
    "    # Determing rolling statistics\n",
    "    rolmean = df[ts].rolling(window = 12, center = False).mean()\n",
    "    rolstd = df[ts].rolling(window = 12, center = False).std()\n",
    "    \n",
    "    # Plot rolling statistics:\n",
    "    orig = plt.plot(df[ts], \n",
    "                    color = 'blue', \n",
    "                    label = 'Original')\n",
    "    mean = plt.plot(rolmean, \n",
    "                    color = 'red', \n",
    "                    label = 'Rolling Mean')\n",
    "    std = plt.plot(rolstd, \n",
    "                   color = 'black', \n",
    "                   label = 'Rolling Std')\n",
    "    plt.legend(loc = 'best')\n",
    "    plt.title('Rolling Mean & Standard Deviation for %s' %(ts))\n",
    "    plt.xticks(rotation = 45)\n",
    "    plt.show(block = False)\n",
    "    plt.close()\n",
    "    \n",
    "    # Perform Dickey-Fuller test:\n",
    "    # Null Hypothesis (H_0): time series is not stationary\n",
    "    # Alternate Hypothesis (H_1): time series is stationary\n",
    "    print('Results of Dickey-Fuller Test:')\n",
    "    dftest = adfuller(df[ts], \n",
    "                      autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], \n",
    "                         index = ['Test Statistic',\n",
    "                                  'p-value',\n",
    "                                  '# Lags Used',\n",
    "                                  'Number of Observations Used'])\n",
    "    for key, value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print(dfoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stationarity(df = df, ts = 'ts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming, Smoothing, Differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next two cells create a dataframe that apply a lot of transformations to the raw series.\n",
    "# Some combinations of transformations are also tested.\n",
    "# This allows to choose the transformation/s that make the data more stationary over time.\n",
    "# Transformations make the time series stationary based on the Dickey-Fuller test when\n",
    "# the p-value = < 0.05.\n",
    "\n",
    "\n",
    "def plot_transformed_data(df, ts, ts_transform):\n",
    "    \"\"\"\n",
    "    Plot transformed and original time series data\n",
    "    \"\"\"\n",
    "    # Plot time series data\n",
    "    f, ax = plt.subplots(1,1)\n",
    "    ax.plot(df[ts])\n",
    "    ax.plot(df[ts_transform], color = 'red')\n",
    "\n",
    "    # Add title\n",
    "    ax.set_title('%s and %s time-series graph' %(ts, ts_transform))\n",
    "\n",
    "    # Rotate x-labels\n",
    "    ax.tick_params(axis = 'x', rotation = 45)\n",
    "\n",
    "    # Add legend\n",
    "    ax.legend([ts, ts_transform])\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation - log ts\n",
    "df['ts_log'] = df['ts'].apply(lambda x: np.log(x))\n",
    "\n",
    "# Transformation - 7-day moving averages of log ts\n",
    "df['ts_log_moving_avg'] = df['ts_log'].rolling(window = 7,\n",
    "                                                               center = False).mean()\n",
    "\n",
    "# Transformation - 7-day moving average ts\n",
    "df['ts_moving_avg'] = df['ts'].rolling(window = 7,\n",
    "                                                       center = False).mean()\n",
    "\n",
    "# Transformation - Difference between logged ts and first-order difference logged ts\n",
    "# df['ts_log_diff'] = df['ts_log'] - df['ts_log'].shift()\n",
    "df['ts_log_diff'] = df['ts_log'].diff()\n",
    "\n",
    "# Transformation - Difference between ts and moving average ts\n",
    "df['ts_moving_avg_diff'] = df['ts'] - df['ts_moving_avg']\n",
    "\n",
    "# Transformation - Difference between logged ts and logged moving average ts\n",
    "df['ts_log_moving_avg_diff'] = df['ts_log'] - df['ts_log_moving_avg']\n",
    "\n",
    "# Transformation - Difference between logged ts and logged moving average ts\n",
    "df_transform = df.dropna()\n",
    "\n",
    "# Transformation - Logged exponentially weighted moving averages (EWMA) ts\n",
    "df_transform['ts_log_ewma'] = df_transform['ts_log'].ewm(halflife = 7,\n",
    "                                                                         ignore_na = False,\n",
    "                                                                         min_periods = 0,\n",
    "                                                                         adjust = True).mean()\n",
    "\n",
    "# Transformation - Difference between logged ts and logged EWMA ts\n",
    "df_transform['ts_log_ewma_diff'] = df_transform['ts_log'] - df_transform['ts_log_ewma']\n",
    "\n",
    "# Display data\n",
    "display(df_transform.head())\n",
    "\n",
    "# Plot data\n",
    "plot_transformed_data(df = df, \n",
    "                      ts = 'ts', \n",
    "                      ts_transform = 'ts_log')\n",
    "# Plot data\n",
    "plot_transformed_data(df = df, \n",
    "                      ts = 'ts_log', \n",
    "                      ts_transform = 'ts_log_moving_avg')\n",
    "\n",
    "# Plot data\n",
    "plot_transformed_data(df = df_transform, \n",
    "                      ts = 'ts', \n",
    "                      ts_transform = 'ts_moving_avg')\n",
    "\n",
    "# Plot data\n",
    "plot_transformed_data(df = df_transform, \n",
    "                      ts = 'ts_log', \n",
    "                      ts_transform = 'ts_log_diff')\n",
    "\n",
    "# Plot data\n",
    "plot_transformed_data(df = df_transform, \n",
    "                      ts = 'ts', \n",
    "                      ts_transform = 'ts_moving_avg_diff')\n",
    "\n",
    "# Plot data\n",
    "plot_transformed_data(df = df_transform, \n",
    "                      ts = 'ts_log', \n",
    "                      ts_transform = 'ts_log_moving_avg_diff')\n",
    "\n",
    "# Plot data\n",
    "plot_transformed_data(df = df_transform, \n",
    "                      ts = 'ts_log', \n",
    "                      ts_transform = 'ts_log_ewma')\n",
    "\n",
    "# Plot data\n",
    "plot_transformed_data(df = df_transform, \n",
    "                      ts = 'ts_log', \n",
    "                      ts_transform = 'ts_log_ewma_diff')\n",
    "\n",
    "# Perform stationarity test\n",
    "test_stationarity(df = df_transform, \n",
    "                  ts = 'ts_log')\n",
    "\n",
    "# Perform stationarity test\n",
    "test_stationarity(df = df_transform, \n",
    "                  ts = 'ts_moving_avg')\n",
    "\n",
    "# Perform stationarity test\n",
    "test_stationarity(df = df_transform, \n",
    "                  ts = 'ts_log_moving_avg')\n",
    "\n",
    "# Perform stationarity test\n",
    "test_stationarity(df = df_transform,\n",
    "                  ts = 'ts_log_diff')\n",
    "\n",
    "# Perform stationarity test\n",
    "test_stationarity(df = df_transform,\n",
    "                  ts = 'ts_moving_avg_diff')\n",
    "\n",
    "# Perform stationarity test\n",
    "test_stationarity(df = df_transform,\n",
    "                  ts = 'ts_log_moving_avg_diff')\n",
    "\n",
    "# Perform stationarity test\n",
    "test_stationarity(df = df_transform, \n",
    "                  ts = 'ts_log_ewma')\n",
    "\n",
    "# Perform stationarity test\n",
    "test_stationarity(df = df_transform,\n",
    "                  ts = 'ts_log_ewma_diff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ARIMA models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acf_pacf(df, ts):\n",
    "    \"\"\" Plot auto-correlation function (ACF) and partial auto-correlation (PACF) plots \"\"\"\n",
    "    f, (ax1, ax2) = plt.subplots(1,2, figsize = (10, 5))\n",
    "    \n",
    "    #Plot ACF: \n",
    "\n",
    "    ax1.plot(lag_acf)\n",
    "    ax1.axhline(y=0,linestyle='--',color='gray')\n",
    "    ax1.axhline(y=-1.96/np.sqrt(len(df[ts])),linestyle='--',color='gray')\n",
    "    ax1.axhline(y=1.96/np.sqrt(len(df[ts])),linestyle='--',color='gray')\n",
    "    ax1.set_title('Autocorrelation Function for %s' %(ts))\n",
    "\n",
    "    #Plot PACF:\n",
    "    ax2.plot(lag_pacf)\n",
    "    ax2.axhline(y=0,linestyle='--',color='gray')\n",
    "    ax2.axhline(y=-1.96/np.sqrt(len(df[ts])),linestyle='--',color='gray')\n",
    "    ax2.axhline(y=1.96/np.sqrt(len(df[ts])),linestyle='--',color='gray')\n",
    "    ax2.set_title('Partial Autocorrelation Function for %s' %(ts))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACF and PACF plots:\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "\n",
    "# determine ACF and PACF\n",
    "lag_acf = acf(np.array(df_transform['ts_log_diff']), nlags = 20)\n",
    "lag_pacf = pacf(np.array(df_transform['ts_log_diff']), nlags = 20)\n",
    "\n",
    "# plot ACF and PACF\n",
    "plot_acf_pacf(df = df_transform, ts = 'ts_log_diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_arima_model(df, ts, p, d, q):\n",
    "    \"\"\"\n",
    "    Run ARIMA model\n",
    "    \"\"\"\n",
    "    from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "    # fit ARIMA model on time series\n",
    "    model = ARIMA(df[ts], order=(p, d, q))  \n",
    "    results_ = model.fit(disp=-1)  \n",
    "\n",
    "    # get lengths correct to calculate RSS\n",
    "    len_results = len(results_.fittedvalues)\n",
    "    ts_modified = df[ts][-len_results:]\n",
    "\n",
    "    # calculate root mean square error (RMSE) and residual sum of squares (RSS)\n",
    "    rss = sum((results_.fittedvalues - ts_modified)**2)\n",
    "    rmse = np.sqrt(rss / len(df[ts]))\n",
    "\n",
    "    # plot fit\n",
    "    plt.plot(df[ts])\n",
    "    plt.plot(results_.fittedvalues, color = 'red')\n",
    "    plt.title('For ARIMA model (%i, %i, %i) for ts %s, RSS: %.4f, RMSE: %.4f' %(p, d, q, ts, rss, rmse))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    return results_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### **WRITE A FUNCTION THAT KEEPS ITERATING FOR THE ( p, d, q ) VALUES TO GET THE BEST FIT.**\n",
    "\n",
    "###  **Very rare having to differenciate 2 times. Once is almost always is enough.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: I do the differencing in the transformation of the data 'ts_log_diff'\n",
    "# AR model with 1st order differencing - ARIMA (1,0,0)\n",
    "\n",
    "\n",
    "model_AR = run_arima_model(df = df_transform, \n",
    "                           ts = 'ts_log_diff', \n",
    "                           p = 1, \n",
    "                           d = 0, \n",
    "                           q = 0)\n",
    "\n",
    "# MA model with 1st order differencing - ARIMA (0,0,1)\n",
    "model_MA = run_arima_model(df = df_transform, \n",
    "                           ts = 'ts_log_diff', \n",
    "                           p = 0, \n",
    "                           d = 0, \n",
    "                           q = 1)\n",
    "\n",
    "# ARMA model with 1st order differencing - ARIMA (1,0,1)\n",
    "model_MA = run_arima_model(df = df_transform, \n",
    "                           ts = 'ts_log_diff', \n",
    "                           p = 1, \n",
    "                           d = 0, \n",
    "                           q = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pystan\n",
    "!pip install fbprophet\n",
    "from fbprophet import Prophet\n",
    "import datetime\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def days_between(d1, d2):\n",
    "    \"\"\"Calculate the number of days between two dates.  D1 is start date (inclusive) and d2 is end date (inclusive)\"\"\"\n",
    "    d1 = datetime.strptime(d1, \"%Y-%m-%d\")\n",
    "    d2 = datetime.strptime(d2, \"%Y-%m-%d\")\n",
    "    return abs((d2 - d1).days + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs for query\n",
    "\n",
    "date_column = 'dt'\n",
    "metric_column = 'ts'\n",
    "table = df\n",
    "start_training_date = '2010-07-03'\n",
    "end_training_date = '2018-09-08'\n",
    "start_forecasting_date = '2018-09-09'\n",
    "end_forecasting_date = '2018-12-31'\n",
    "year_to_estimate = '2018'\n",
    "\n",
    "# Inputs for forecasting\n",
    "\n",
    "# future_num_points\n",
    "# If doing different time intervals, change future_num_points\n",
    "future_num_points = days_between(start_forecasting_date, end_forecasting_date)\n",
    "\n",
    "cap = None # 2e6\n",
    "\n",
    "# growth: default = 'linear'\n",
    "# Can also choose 'logistic'\n",
    "growth = 'linear'\n",
    "\n",
    "# n_changepoints: default = 25, uniformly placed in first 80% of time series\n",
    "n_changepoints = 25 \n",
    "\n",
    "# changepoint_prior_scale: default = 0.05\n",
    "# Increasing it will make the trend more flexible\n",
    "changepoint_prior_scale = 0.05 \n",
    "\n",
    "# changpoints: example = ['2016-01-01']\n",
    "changepoints = None \n",
    "\n",
    "# holidays_prior_scale: default = 10\n",
    "# If you find that the holidays are overfitting, you can adjust their prior scale to smooth them\n",
    "holidays_prior_scale = 10 \n",
    "\n",
    "# interval_width: default = 0.8\n",
    "interval_width = 0.8 \n",
    "\n",
    "# mcmc_samples: default = 0\n",
    "# By default Prophet will only return uncertainty in the trend and observation noise.\n",
    "# To get uncertainty in seasonality, you must do full Bayesian sampling. \n",
    "# Replaces typical MAP estimation with MCMC sampling, and takes MUCH LONGER - e.g., 10 minutes instead of 10 seconds.\n",
    "# If you do full sampling, then you will see the uncertainty in seasonal components when you plot:\n",
    "mcmc_samples = 0\n",
    "\n",
    "# holiday: default = None\n",
    "# thanksgiving = pd.DataFrame({\n",
    "#   'holiday': 'thanksgiving',\n",
    "#   'ds': pd.to_datetime(['2014-11-27', '2015-11-26',\n",
    "#                         '2016-11-24', '2017-11-23']),\n",
    "#   'lower_window': 0,\n",
    "#   'upper_window': 4,\n",
    "# })\n",
    "# christmas = pd.DataFrame({\n",
    "#   'holiday': 'christmas',\n",
    "#   'ds': pd.to_datetime(['2014-12-25', '2015-12-25', \n",
    "#                         '2016-12-25','2017-12-25']),\n",
    "#   'lower_window': -1,\n",
    "#   'upper_window': 0,\n",
    "# })\n",
    "# holidays = pd.concat((thanksgiving,christmas))\n",
    "holidays = None\n",
    "\n",
    "daily_seasonality = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get relevant data - note: could also try this with ts_log_diff\n",
    "df_prophet = df_transform[['ts']] # can try with ts_log_diff\n",
    "\n",
    "# reset index\n",
    "df_prophet = df_prophet.reset_index()\n",
    "\n",
    "# rename columns\n",
    "df_prophet = df_prophet.rename(columns = {'ds': 'ds', 'ts': 'y'}) # can try with ts_log_diff\n",
    "\n",
    "# Change 'ds' type from datetime to date (necessary for FB Prophet)\n",
    "df_prophet['ds'] = pd.to_datetime(df_prophet['ds'])\n",
    "\n",
    "# Change 'y' type to numeric (necessary for FB Prophet)\n",
    "df_prophet['y'] = pd.to_numeric(df_prophet['y'], errors='ignore')\n",
    "\n",
    "# Remove any outliers\n",
    "# df.loc[(df_['ds'] > '2016-12-13') & (df_['ds'] < '2016-12-19'), 'y'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_daily_forecast(df,\n",
    "                          cap,\n",
    "                          holidays,\n",
    "                          growth,\n",
    "                          n_changepoints = 25,\n",
    "                          changepoint_prior_scale = 0.05,\n",
    "                          changepoints = None,\n",
    "                          holidays_prior_scale = 10,\n",
    "                          interval_width = 0.8,\n",
    "                          mcmc_samples = 1,\n",
    "                          future_num_points = 10, \n",
    "                          daily_seasonality = True):\n",
    "    \"\"\"\n",
    "    Create forecast\n",
    "    \"\"\"\n",
    "\n",
    "    # Create copy of dataframe\n",
    "    df_ = df.copy()\n",
    "\n",
    "    # Add in growth parameter, which can change over time\n",
    "    #     df_['cap'] = max(df_['y']) if cap is None else cap\n",
    "\n",
    "    # Create model object and fit to dataframe\n",
    "    m = Prophet(growth = growth,\n",
    "              n_changepoints = n_changepoints,\n",
    "              changepoint_prior_scale = changepoint_prior_scale,\n",
    "              changepoints = changepoints,\n",
    "              holidays = holidays,\n",
    "              holidays_prior_scale = holidays_prior_scale,\n",
    "              interval_width = interval_width,\n",
    "              mcmc_samples = mcmc_samples, \n",
    "              daily_seasonality = daily_seasonality)\n",
    "\n",
    "    # Fit model with dataframe\n",
    "    m.fit(df_)\n",
    "\n",
    "    # Create dataframe for predictions\n",
    "    future = m.make_future_dataframe(periods = future_num_points)\n",
    "    #     future['cap'] = max(df_['y']) if cap is None else cap\n",
    "\n",
    "    # Create predictions\n",
    "    fcst = m.predict(future)\n",
    "\n",
    "    # Plot\n",
    "    m.plot(fcst);\n",
    "    m.plot_components(fcst)\n",
    "\n",
    "    return fcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = create_daily_forecast(df_prophet,\n",
    "                             cap,\n",
    "                             holidays,\n",
    "                             growth,\n",
    "                             n_changepoints,\n",
    "                             changepoint_prior_scale,\n",
    "                             changepoints, \n",
    "                             holidays_prior_scale,\n",
    "                             interval_width,\n",
    "                             mcmc_samples,\n",
    "                             future_num_points, \n",
    "                             daily_seasonality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mape(y_true, y_pred):\n",
    "    \"\"\" Calculate mean absolute percentage error (MAPE)\"\"\"\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def calculate_mpe(y_true, y_pred):\n",
    "    \"\"\" Calculate mean percentage error (MPE)\"\"\"\n",
    "    return np.mean((y_true - y_pred) / y_true) * 100\n",
    "\n",
    "def calculate_mae(y_true, y_pred):\n",
    "    \"\"\" Calculate mean absolute error (MAE)\"\"\"\n",
    "    return np.mean(np.abs(y_true - y_pred)) * 100\n",
    "\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    \"\"\" Calculate root mean square error (RMSE)\"\"\"\n",
    "    return np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "\n",
    "def print_error_metrics(y_true, y_pred):\n",
    "    print('MAPE: %f'%calculate_mape(y_true, y_pred))\n",
    "    print('MPE: %f'%calculate_mpe(y_true, y_pred))\n",
    "    print('MAE: %f'%calculate_mae(y_true, y_pred))\n",
    "    print('RMSE: %f'%calculate_rmse(y_true, y_pred))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_error_metrics(y_true = df_prophet['y'], y_pred = fcst['yhat'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
